{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "#download assets from nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "def tfidf(corpus):\n",
    "    '''\n",
    "    Computes the TF-IDF (term frequency - inverse document frequency) matrix\n",
    "\n",
    "    Args\n",
    "    - corpus: a list of documents\n",
    "\n",
    "    Returns\n",
    "    - tfidfVec: an m x n matrix of the corpus. m = number of documents, n = number of different terms used in the documents\n",
    "    - vocab: all the unique words used in the corpus, excluding stop words\n",
    "    '''\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words = stopwords.words('english'))\n",
    "    #vectorizer = CountVectorizer(stop_words='english')\n",
    "    tfidfVec = vectorizer.fit_transform(corpus)\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "        \n",
    "    return tfidfVec, vocab\n",
    "\n",
    "def svd(tfidfVec):\n",
    "    '''\n",
    "    Gives the singular value decomposition of an m x n matrix.\n",
    "    A = U * sigma * V^t\n",
    "    \n",
    "    Args\n",
    "    - tfidfVec: an m x n matrix. m = number of documents or sentences, n = number of terms\n",
    "\n",
    "    Returns\n",
    "    - u: an m x r matrix of left singular values (document-topic table). r = number of topics\n",
    "    - sigma: an r x r diagonal matrix of singular values in decreasing order across the diagonal\n",
    "    - V^t: an n x r matrix of right singular values (term-topic table)\n",
    "    '''\n",
    "\n",
    "    lsa = TruncatedSVD(n_components=10, n_iter=20)\n",
    "    u = lsa.fit_transform(tfidfVec)\n",
    "    sigma = lsa.singular_values_\n",
    "    vt = lsa.components_.T\n",
    "\n",
    "    return u, sigma, vt\n",
    "\n",
    "def createWordToSentenceMap(corpus):\n",
    "    wordToSentence = {}\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "\n",
    "    for i, doc in enumerate(corpus):\n",
    "        #remove punctuation while preserving contractions in text\n",
    "        sanitizeText = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "        tokenized = word_tokenize(sanitizeText)\n",
    "        #remove duplicate words\n",
    "        tokenized = list(set([word.lower() for word in tokenized]))\n",
    "\n",
    "        for word in tokenized:\n",
    "            if word not in stopWords:\n",
    "                if word not in wordToSentence:\n",
    "                    wordToSentence[word] = [i]\n",
    "                else:\n",
    "                    wordToSentence[word].append(i)\n",
    "    \n",
    "    return wordToSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'two': [0], 'methods': [0, 1, 2], 'sentences': [0, 1, 2], 'paper': [0], 'summarization': [0], 'ranking': [0], 'original': [0], 'extracting': [0], 'summaries': [0], 'generic': [0], 'text': [0], 'propose': [0], 'documents': [0], 'create': [0], 'identify': [1], 'second': [1], 'rank': [1], 'sentence': [1], 'semantically': [1], 'uses': [1], 'relevances': [1], 'summary': [1], 'semantic': [1], 'analysis': [1], 'creations': [1], 'first': [1], 'standard': [1], 'important': [1], 'latent': [1], 'ir': [1], 'method': [1], 'technique': [1], 'different': [2], 'select': [2], 'strive': [2], 'highly': [2], 'ranked': [2]}\n  (0, 4)\t0.2523960843862897\n  (0, 15)\t0.2523960843862897\n  (0, 27)\t0.14906919332483493\n  (0, 5)\t0.2523960843862897\n  (0, 20)\t0.2523960843862897\n  (0, 30)\t0.2523960843862897\n  (0, 1)\t0.2523960843862897\n  (0, 14)\t0.14906919332483493\n  (0, 31)\t0.2523960843862897\n  (0, 34)\t0.5047921687725794\n  (0, 7)\t0.2523960843862897\n  (0, 35)\t0.2523960843862897\n  (0, 17)\t0.2523960843862897\n  (0, 16)\t0.2523960843862897\n  (1, 2)\t0.20122046214443134\n  (1, 32)\t0.20122046214443134\n  (1, 10)\t0.20122046214443134\n  (1, 25)\t0.20122046214443134\n  (1, 9)\t0.20122046214443134\n  (1, 33)\t0.20122046214443134\n  (1, 0)\t0.20122046214443134\n  (1, 24)\t0.20122046214443134\n  (1, 12)\t0.20122046214443134\n  (1, 22)\t0.20122046214443134\n  (1, 21)\t0.20122046214443134\n  (1, 26)\t0.20122046214443134\n  (1, 18)\t0.20122046214443134\n  (1, 11)\t0.20122046214443134\n  (1, 28)\t0.20122046214443134\n  (1, 36)\t0.4024409242888627\n  (1, 13)\t0.4024409242888627\n  (1, 6)\t0.20122046214443134\n  (1, 27)\t0.11884404643303671\n  (1, 14)\t0.11884404643303671\n  (2, 3)\t0.4189401020758947\n  (2, 19)\t0.4189401020758947\n  (2, 8)\t0.4189401020758947\n  (2, 23)\t0.4189401020758947\n  (2, 29)\t0.4189401020758947\n  (2, 27)\t0.24743277305481848\n  (2, 14)\t0.24743277305481848\n----------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "                                           Documents    topic1    topic2  \\\n0  In this paper, we propose two generic text sum...  0.606851 -0.576719   \n1  The first method uses standard IR methods to r...  0.539111  0.787951   \n2  Both methods strive to select sentences that a...  0.674182 -0.110965   \n\n     topic3  \n0 -0.546925  \n1 -0.297477  \n2  0.730182  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Documents</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>In this paper, we propose two generic text sum...</td>\n      <td>0.606851</td>\n      <td>-0.576719</td>\n      <td>-0.546925</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>The first method uses standard IR methods to r...</td>\n      <td>0.539111</td>\n      <td>0.787951</td>\n      <td>-0.297477</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Both methods strive to select sentences that a...</td>\n      <td>0.674182</td>\n      <td>-0.110965</td>\n      <td>0.730182</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------\n[1.05519232 0.98274323 0.95957538]\n----------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "            Terms    topic1    topic2    topic3\n0        analysis  0.097429  0.164169 -0.065008\n1          create  0.137563 -0.150718 -0.149917\n2       creations  0.097429  0.164169 -0.065008\n3       different  0.253668 -0.048135  0.332219\n4       documents  0.137563 -0.150718 -0.149917\n5      extracting  0.137563 -0.150718 -0.149917\n6           first  0.097429  0.164169 -0.065008\n7         generic  0.137563 -0.150718 -0.149917\n8          highly  0.253668 -0.048135  0.332219\n9        identify  0.097429  0.164169 -0.065008\n10      important  0.097429  0.164169 -0.065008\n11             ir  0.097429  0.164169 -0.065008\n12         latent  0.097429  0.164169 -0.065008\n13         method  0.194858  0.328338 -0.130016\n14        methods  0.288610 -0.020485  0.069275\n15       original  0.137563 -0.150718 -0.149917\n16          paper  0.137563 -0.150718 -0.149917\n17        propose  0.137563 -0.150718 -0.149917\n18           rank  0.097429  0.164169 -0.065008\n19         ranked  0.253668 -0.048135  0.332219\n20        ranking  0.137563 -0.150718 -0.149917\n21     relevances  0.097429  0.164169 -0.065008\n22         second  0.097429  0.164169 -0.065008\n23         select  0.253668 -0.048135  0.332219\n24       semantic  0.097429  0.164169 -0.065008\n25   semantically  0.097429  0.164169 -0.065008\n26       sentence  0.097429  0.164169 -0.065008\n27      sentences  0.288610 -0.020485  0.069275\n28       standard  0.097429  0.164169 -0.065008\n29         strive  0.253668 -0.048135  0.332219\n30      summaries  0.137563 -0.150718 -0.149917\n31  summarization  0.137563 -0.150718 -0.149917\n32        summary  0.097429  0.164169 -0.065008\n33      technique  0.097429  0.164169 -0.065008\n34           text  0.275126 -0.301437 -0.299835\n35            two  0.137563 -0.150718 -0.149917\n36           uses  0.194858  0.328338 -0.130016",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>topic1</th>\n      <th>topic2</th>\n      <th>topic3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>analysis</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>create</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>creations</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>different</td>\n      <td>0.253668</td>\n      <td>-0.048135</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>documents</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>extracting</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>first</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>generic</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>highly</td>\n      <td>0.253668</td>\n      <td>-0.048135</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>identify</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>important</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>ir</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>latent</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>method</td>\n      <td>0.194858</td>\n      <td>0.328338</td>\n      <td>-0.130016</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>methods</td>\n      <td>0.288610</td>\n      <td>-0.020485</td>\n      <td>0.069275</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>original</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>paper</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>propose</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>rank</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>ranked</td>\n      <td>0.253668</td>\n      <td>-0.048135</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>ranking</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>relevances</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>second</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>select</td>\n      <td>0.253668</td>\n      <td>-0.048135</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>semantic</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>semantically</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>sentence</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>sentences</td>\n      <td>0.288610</td>\n      <td>-0.020485</td>\n      <td>0.069275</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>standard</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>strive</td>\n      <td>0.253668</td>\n      <td>-0.048135</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>summaries</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>summarization</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>summary</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>technique</td>\n      <td>0.097429</td>\n      <td>0.164169</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>text</td>\n      <td>0.275126</td>\n      <td>-0.301437</td>\n      <td>-0.299835</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>two</td>\n      <td>0.137563</td>\n      <td>-0.150718</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>uses</td>\n      <td>0.194858</td>\n      <td>0.328338</td>\n      <td>-0.130016</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "            Terms    topic1\n27      sentences  0.288610\n14        methods  0.288610\n34           text  0.275126\n23         select  0.253668\n3       different  0.253668\n29         strive  0.253668\n19         ranked  0.253668\n8          highly  0.253668\n13         method  0.194858\n36           uses  0.194858\n31  summarization  0.137563\n7         generic  0.137563\n15       original  0.137563\n16          paper  0.137563\n17        propose  0.137563\n1          create  0.137563\n5      extracting  0.137563\n20        ranking  0.137563\n4       documents  0.137563\n35            two  0.137563\n30      summaries  0.137563\n32        summary  0.097429\n26       sentence  0.097429\n33      technique  0.097429\n28       standard  0.097429\n18           rank  0.097429\n25   semantically  0.097429\n24       semantic  0.097429\n22         second  0.097429\n21     relevances  0.097429\n12         latent  0.097429\n11             ir  0.097429\n10      important  0.097429\n9        identify  0.097429\n6           first  0.097429\n2       creations  0.097429\n0        analysis  0.097429",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>topic1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>27</td>\n      <td>sentences</td>\n      <td>0.288610</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>methods</td>\n      <td>0.288610</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>text</td>\n      <td>0.275126</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>select</td>\n      <td>0.253668</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>different</td>\n      <td>0.253668</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>strive</td>\n      <td>0.253668</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>ranked</td>\n      <td>0.253668</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>highly</td>\n      <td>0.253668</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>method</td>\n      <td>0.194858</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>uses</td>\n      <td>0.194858</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>summarization</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>generic</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>original</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>paper</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>propose</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>create</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>extracting</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>ranking</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>documents</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>two</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>summaries</td>\n      <td>0.137563</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>summary</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>sentence</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>technique</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>standard</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>rank</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>semantically</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>semantic</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>second</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>relevances</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>latent</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>ir</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>important</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>identify</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>first</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>creations</td>\n      <td>0.097429</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>analysis</td>\n      <td>0.097429</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "            Terms    topic2\n36           uses  0.328338\n13         method  0.328338\n12         latent  0.164169\n33      technique  0.164169\n32        summary  0.164169\n28       standard  0.164169\n26       sentence  0.164169\n25   semantically  0.164169\n24       semantic  0.164169\n22         second  0.164169\n21     relevances  0.164169\n18           rank  0.164169\n11             ir  0.164169\n9        identify  0.164169\n6           first  0.164169\n10      important  0.164169\n2       creations  0.164169\n0        analysis  0.164169\n27      sentences -0.020485\n14        methods -0.020485\n19         ranked -0.048135\n3       different -0.048135\n8          highly -0.048135\n23         select -0.048135\n29         strive -0.048135\n1          create -0.150718\n5      extracting -0.150718\n15       original -0.150718\n4       documents -0.150718\n16          paper -0.150718\n30      summaries -0.150718\n31  summarization -0.150718\n17        propose -0.150718\n20        ranking -0.150718\n35            two -0.150718\n7         generic -0.150718\n34           text -0.301437",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>topic2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>36</td>\n      <td>uses</td>\n      <td>0.328338</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>method</td>\n      <td>0.328338</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>latent</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>technique</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>summary</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>standard</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>sentence</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>semantically</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>semantic</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>second</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>relevances</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>rank</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>ir</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>identify</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>first</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>important</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>creations</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>analysis</td>\n      <td>0.164169</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>sentences</td>\n      <td>-0.020485</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>methods</td>\n      <td>-0.020485</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>ranked</td>\n      <td>-0.048135</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>different</td>\n      <td>-0.048135</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>highly</td>\n      <td>-0.048135</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>select</td>\n      <td>-0.048135</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>strive</td>\n      <td>-0.048135</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>create</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>extracting</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>original</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>documents</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>paper</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>summaries</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>summarization</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>propose</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>ranking</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>two</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>generic</td>\n      <td>-0.150718</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>text</td>\n      <td>-0.301437</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "            Terms    topic3\n23         select  0.332219\n3       different  0.332219\n19         ranked  0.332219\n29         strive  0.332219\n8          highly  0.332219\n27      sentences  0.069275\n14        methods  0.069275\n18           rank -0.065008\n28       standard -0.065008\n24       semantic -0.065008\n25   semantically -0.065008\n26       sentence -0.065008\n11             ir -0.065008\n12         latent -0.065008\n22         second -0.065008\n10      important -0.065008\n9        identify -0.065008\n6           first -0.065008\n32        summary -0.065008\n33      technique -0.065008\n21     relevances -0.065008\n2       creations -0.065008\n0        analysis -0.065008\n36           uses -0.130016\n13         method -0.130016\n1          create -0.149917\n20        ranking -0.149917\n17        propose -0.149917\n16          paper -0.149917\n15       original -0.149917\n7         generic -0.149917\n30      summaries -0.149917\n31  summarization -0.149917\n5      extracting -0.149917\n4       documents -0.149917\n35            two -0.149917\n34           text -0.299835",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Terms</th>\n      <th>topic3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>23</td>\n      <td>select</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>different</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>ranked</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>strive</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>highly</td>\n      <td>0.332219</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>sentences</td>\n      <td>0.069275</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>methods</td>\n      <td>0.069275</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>rank</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>standard</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>semantic</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>semantically</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>sentence</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>ir</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>latent</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>second</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>important</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>identify</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>first</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>summary</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>technique</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>relevances</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>creations</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>analysis</td>\n      <td>-0.065008</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>uses</td>\n      <td>-0.130016</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>method</td>\n      <td>-0.130016</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>create</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>ranking</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>propose</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>paper</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>original</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>generic</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>summaries</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>summarization</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>extracting</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>documents</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>two</td>\n      <td>-0.149917</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>text</td>\n      <td>-0.299835</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'In this paper, we propose two generic text summarization methods that create text summaries by ranking and extracting sentences from the original documents.',\n",
    "    'The first method uses standard IR methods to rank sentence relevances, while the second method uses the latent semantic analysis technique to identify semantically important sentences, for summary creations.',\n",
    "    'Both methods strive to select sentences that are highly ranked and different from each other.'\n",
    "]\n",
    "\n",
    "tfidfVec, vocab = tfidf(corpus)\n",
    "wordToSentence = createWordToSentenceMap(corpus)\n",
    "\n",
    "print(wordToSentence)\n",
    "print(tfidfVec)\n",
    "print('----------------------------------------------------------')\n",
    "\n",
    "svdVec, sigma, vt = svd(tfidfVec)\n",
    "numTopics = svdVec.shape[1] + 1\n",
    "\n",
    "df = pd.DataFrame(svdVec, columns=[f'topic{str(i)}' for i in range(1, numTopics)])\n",
    "docCol = pd.DataFrame({'Documents': corpus})\n",
    "df = pd.concat([docCol, df], axis = 1)\n",
    "\n",
    "display(df)\n",
    "print('----------------------------------------------------------')\n",
    "print(sigma)\n",
    "\n",
    "print('----------------------------------------------------------')\n",
    "\n",
    "dfVt = pd.DataFrame(vt, columns=[f'topic{str(i)}' for i in range(1, numTopics)])\n",
    "vocabCol = pd.DataFrame({'Terms': vocab})\n",
    "dfVt = pd.concat([vocabCol, dfVt], axis = 1)\n",
    "\n",
    "display(dfVt)\n",
    "\n",
    "for i in range(1, numTopics):\n",
    "    dfVtSort = dfVt.sort_values(by=f'topic{i}', ascending=False)\n",
    "    display(dfVtSort[['Terms', f'topic{i}']])\n",
    "print('----------------------------------------------------------')\n",
    "\n",
    "\n",
    "#df = pd.DataFrame()\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summarizerEnv",
   "language": "python",
   "name": "summarizerenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}